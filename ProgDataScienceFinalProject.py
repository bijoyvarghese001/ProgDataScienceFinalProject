# -*- coding: utf-8 -*-
"""ProgDataScienceFinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WE6c_LkQlL0O_jS7AyK1ZjXk_7qkatxv

**Step 1:** 	Set up a Git repository to allow you to collaborate on the Python solution

GIT hub repository is created and is available on below path
**https://github.com/bijoyvarghese001/ProgDataScienceFinalProject**

**Step 2:**	Read the daily confirmed cases and deaths into two dataframes can be found at this github page:
a)	confirmed_cases_url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
b)	deaths_url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"
"""

import pandas as pd

confirmed_cases_url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv"
deaths_url = "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv"

confirmed_cases_df = pd.read_csv(confirmed_cases_url)
deaths_df = pd.read_csv(deaths_url)
print(confirmed_cases_df)
print(deaths_df)

"""**Step 3:** Use pandas to create a dataframe that aggregates and sums both confirmed cases and deaths on a global level"""

#global_confirmed_cases_df = confirmed_cases_df.groupby('Country/Region').sum().iloc[:, 4:]
#global_deaths_df = deaths_df.groupby('Country/Region').sum().iloc[:, 4:]

#global_df = pd.concat([global_confirmed_cases_df.sum(axis=0), global_deaths_df.sum(axis=0)], axis=1)
#global_df.columns = ['Confirmed Cases', 'Deaths']

# aggregate and sum the confirmed cases and deaths on a global level
global_confirmed_cases_df = confirmed_cases_df.iloc[:, 4:].sum(axis=0)
global_deaths_df = deaths_df.iloc[:, 4:].sum(axis=0)
global_df = pd.DataFrame({'Confirmed Cases': global_confirmed_cases_df, 'Deaths': global_deaths_df})
print(global_df)

"""**Step 4:**	Research a stock for each below that reflects the following industries (it will be used in the next step):
a)	Overall American Market
b)	Overall Canadian Market
c)	Travel sector
d)	The Real Estate sector
e)	Precious metals (Gold, Silver, Platinum, etc)

"""

import requests

apikey = '95NQ9UEXL1RBR75Z'

overall_american_market = 'AAPL'
overall_canadian_market = 'RY.TO'
travel_sector = 'DAL'
real_estate_sector = 'SPG'
precious_metals = 'GLD'

"""**Step 5:** Use AlphaVantage (the stock API used earlier in the course) to get the daily high and low prices for your selected stocks"""

def readSelectedStockDetails(symbol, stockMarketType):
    request_url = f'https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={symbol}&apikey={apikey}'
    response = requests.get(request_url)
    data = response.json()['Time Series (Daily)']
    data_df = pd.DataFrame.from_dict(data, orient='index')
    data_df.columns = ['open', stockMarketType+'(high)', stockMarketType+'(low)', 'close', 'adjusted close', 'volume','divident amount','split coefficient']
    return data_df[[stockMarketType+'(high)', stockMarketType+'(low)']]

overall_american_market_df = readSelectedStockDetails(overall_american_market, 'American Market')
print(overall_american_market_df)
overall_canadian_market_df = readSelectedStockDetails(overall_canadian_market, 'Canadian Market')
print(overall_canadian_market_df)
travel_sector_df = readSelectedStockDetails(travel_sector, 'Travel Sector')
print(travel_sector_df)
real_estate_sector_df = readSelectedStockDetails(real_estate_sector, 'RealEstate Sector')
print(real_estate_sector_df)
precious_metals_df = readSelectedStockDetails(precious_metals, 'Precious Metals')
print(precious_metals_df)

"""**Step 6:**	Append that info to the data frame created in step 3"""

# convert the index to datetime format
overall_american_market_df.index = pd.to_datetime(overall_american_market_df.index)
# format the date index as '1/25/20'
overall_american_market_df.index = overall_american_market_df.index.strftime('%-m/%-d/%y')
# convert the index to datetime format
overall_canadian_market_df.index = pd.to_datetime(overall_canadian_market_df.index)
# format the date index as '1/25/20'
overall_canadian_market_df.index = overall_canadian_market_df.index.strftime('%-m/%-d/%y')
# convert the index to datetime format
travel_sector_df.index = pd.to_datetime(travel_sector_df.index)
# format the date index as '1/25/20'
travel_sector_df.index = travel_sector_df.index.strftime('%-m/%-d/%y')
# convert the index to datetime format
real_estate_sector_df.index = pd.to_datetime(real_estate_sector_df.index)
# format the date index as '1/25/20'
real_estate_sector_df.index = real_estate_sector_df.index.strftime('%-m/%-d/%y')
# convert the index to datetime format
precious_metals_df.index = pd.to_datetime(precious_metals_df.index)
# format the date index as '1/25/20'
precious_metals_df.index = precious_metals_df.index.strftime('%-m/%-d/%y')

#Merge all the data into the Global dataframe created in Step3
global_df = pd.merge(global_df, overall_american_market_df, how='left', left_index=True, right_index=True)
global_df = pd.merge(global_df, overall_canadian_market_df, how='left', left_index=True, right_index=True)
global_df = pd.merge(global_df, travel_sector_df, how='left', left_index=True, right_index=True)
global_df = pd.merge(global_df, real_estate_sector_df, how='left', left_index=True, right_index=True)
global_df = pd.merge(global_df, precious_metals_df, how='left', left_index=True, right_index=True)

#Remove the rows with null values
global_df = global_df.dropna()
print(global_df)




